#!/usr/bin/env python3
"""
Bitrix24 ETL Service - –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Bitrix24 CRM –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ Supabase PostgreSQL
"""

import os
import sys
import time
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List
import requests
from supabase import create_client, Client

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('logs/bitrix24_etl.log')
    ]
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
BITRIX_WEBHOOK = os.getenv('BITRIX_WEBHOOK', '').rstrip('/') + '/'  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–ª–µ—à –≤ –∫–æ–Ω—Ü–µ
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
SYNC_MODE = os.getenv('SYNC_MODE', 'full')
HOURS_BACK = int(os.getenv('HOURS_BACK', '24'))

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not all([BITRIX_WEBHOOK, SUPABASE_URL, SUPABASE_KEY]):
    logger.error("‚ùå Missing required environment variables!")
    logger.error(f"   BITRIX_WEBHOOK: {'‚úì' if BITRIX_WEBHOOK else '‚úó'}")
    logger.error(f"   SUPABASE_URL: {'‚úì' if SUPABASE_URL else '‚úó'}")
    logger.error(f"   SUPABASE_KEY: {'‚úì' if SUPABASE_KEY else '‚úó'}")
    sys.exit(1)


class Bitrix24ETL:
    """ETL —Å–µ—Ä–≤–∏—Å –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Bitrix24 –≤ Supabase"""
    
    def __init__(self):
        self.bitrix_url = BITRIX_WEBHOOK
        self.supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
        self.rate_limit_delay = 0.5
        
    # ==================== –£–¢–ò–õ–ò–¢–´ ====================
    
    @staticmethod
    def safe_int(value: Any, default: Optional[int] = None) -> Optional[int]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ int"""
        if value is None or value == '' or value == 'null':
            return default
        try:
            return int(float(value))
        except (ValueError, TypeError):
            return default
    
    @staticmethod
    def safe_float(value: Any, default: Optional[float] = None) -> Optional[float]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ float"""
        if value is None or value == '' or value == 'null':
            return default
        try:
            return float(value)
        except (ValueError, TypeError):
            return default
    
    @staticmethod
    def safe_datetime(value: Any) -> Optional[str]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã –≤ ISO —Ñ–æ—Ä–º–∞—Ç"""
        if not value or value == '' or value == 'null':
            return None
        try:
            if isinstance(value, str):
                value = value.replace('Z', '+00:00')
                dt = datetime.fromisoformat(value)
                return dt.isoformat()
            return None
        except (ValueError, TypeError):
            return None
    
    @staticmethod
    def safe_bool(value: Any) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ bool"""
        if value is None or value == '':
            return False
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.upper() in ('Y', 'YES', 'TRUE', '1')
        return bool(value)
    
    def bitrix_request(self, method: str, params: Optional[Dict] = None) -> List[Dict]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ Bitrix24 API —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
        all_results = []
        start = 0
        
        if params is None:
            params = {}
        
        while True:
            request_params = {**params, 'start': start}
            url = f"{self.bitrix_url}{method}.json"
            
            try:
                time.sleep(self.rate_limit_delay)
                response = requests.get(url, params=request_params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if 'result' not in data:
                    break
                
                results = data['result']
                if not results:
                    break
                
                all_results.extend(results)
                
                total = data.get('total', 0)
                if len(all_results) >= total or len(results) < 50:
                    break
                
                start += 50
                
            except Exception as e:
                logger.error(f"‚ùå Error in Bitrix24 request {method}: {e}")
                break
        
        return all_results
    
    def log_sync_start(self, entity_type: str) -> int:
        """–ó–∞–ø–∏—Å–∞—Ç—å –Ω–∞—á–∞–ª–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        try:
            result = self.supabase.table('sync_log').insert({
                'sync_type': SYNC_MODE,
                'entity_type': entity_type,
                'status': 'running',
                'started_at': datetime.utcnow().isoformat(),
                'records_processed': 0
            }).execute()
            return result.data[0]['id']
        except Exception as e:
            logger.error(f"‚ùå Error logging sync start: {e}")
            return 0
    
    def log_sync_end(self, sync_id: int, status: str, records: int, error_msg: Optional[str] = None):
        """–ó–∞–ø–∏—Å–∞—Ç—å –æ–∫–æ–Ω—á–∞–Ω–∏–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        try:
            self.supabase.table('sync_log').update({
                'status': status,
                'finished_at': datetime.utcnow().isoformat(),
                'records_processed': records,
                'error_message': error_msg
            }).eq('id', sync_id).execute()
        except Exception as e:
            logger.error(f"‚ùå Error logging sync end: {e}")
    
    # ==================== –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–ê–ù–ù–´–• ====================
    
    def extract_managers(self) -> int:
        """–ò–∑–≤–ª–µ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤)"""
        logger.info("üì• Extracting managers...")
        sync_id = self.log_sync_start('managers')
        
        try:
            # –ë–ï–ó –§–ò–õ–¨–¢–†–ê - –±–µ—Ä—ë–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            users = self.bitrix_request('user.get')
            
            processed = 0
            for user in users:
                user_data = {
                    'id': self.safe_int(user['ID']),
                    'name': user.get('NAME'),
                    'last_name': user.get('LAST_NAME'),
                    'email': user.get('EMAIL'),
                    'work_position': user.get('WORK_POSITION'),
                    'personal_phone': user.get('PERSONAL_PHONE'),
                    'personal_mobile': user.get('PERSONAL_MOBILE'),
                    'raw_data': user
                }
                
                self.supabase.table('managers').upsert(user_data).execute()
                processed += 1
            
            logger.info(f"  ‚úÖ Managers extracted: {processed}")
            self.log_sync_end(sync_id, 'completed', processed)
            return processed
            
        except Exception as e:
            logger.error(f"  ‚ùå Error extracting managers: {e}")
            self.log_sync_end(sync_id, 'failed', 0, str(e))
            return 0
    
    def extract_contacts(self) -> int:
        """–ò–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–∞–∫—Ç—ã"""
        logger.info("üì• Extracting contacts...")
        sync_id = self.log_sync_start('contacts')
        
        processed = 0
        try:
            params = {}
            
            if SYNC_MODE == 'incremental':
                cutoff_time = (datetime.utcnow() - timedelta(hours=HOURS_BACK)).isoformat()
                params['filter'] = {'>DATE_MODIFY': cutoff_time}
            
            contacts = self.bitrix_request('crm.contact.list', params)
            
            batch = []
            
            for contact in contacts:
                # EMAIL –∏ PHONE –ø—Ä–∏—Ö–æ–¥—è—Ç –∫–∞–∫ –º–∞—Å—Å–∏–≤—ã
                email_value = None
                if contact.get('EMAIL') and isinstance(contact['EMAIL'], list) and len(contact['EMAIL']) > 0:
                    email_value = contact['EMAIL'][0].get('VALUE')
                
                phone_value = None
                if contact.get('PHONE') and isinstance(contact['PHONE'], list) and len(contact['PHONE']) > 0:
                    phone_value = contact['PHONE'][0].get('VALUE')
                
                # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω–æ–µ –∏–º—è
                name_parts = [
                    contact.get('NAME'),
                    contact.get('SECOND_NAME'),
                    contact.get('LAST_NAME')
                ]
                full_name = ' '.join(filter(None, name_parts)) or None
                
                contact_data = {
                    'id': self.safe_int(contact['ID']),
                    'name': contact.get('NAME') or None,
                    'last_name': contact.get('LAST_NAME') or None,
                    'second_name': contact.get('SECOND_NAME') or None,
                    'full_name': full_name,
                    'email': email_value,
                    'phone': phone_value,
                    'post': contact.get('POST') or None,
                    'birthdate': self.safe_datetime(contact.get('BIRTHDATE')),
                    'date_create': self.safe_datetime(contact.get('DATE_CREATE')),
                    'date_modify': self.safe_datetime(contact.get('DATE_MODIFY')),
                    'company_id': self.safe_int(contact.get('COMPANY_ID')),
                    'assigned_by_id': self.safe_int(contact.get('ASSIGNED_BY_ID')),
                    'created_by_id': self.safe_int(contact.get('CREATED_BY_ID')),
                    'source_id': contact.get('SOURCE_ID') or None,
                    'source_description': contact.get('SOURCE_DESCRIPTION') or None,
                    'raw_data': contact
                }
                
                batch.append(contact_data)
                processed += 1
                
                if len(batch) >= 50:
                    self.supabase.table('contacts').upsert(batch).execute()
                    logger.info(f"  üìä Contacts extracted: {processed}")
                    batch = []
            
            if batch:
                self.supabase.table('contacts').upsert(batch).execute()
            
            logger.info(f"  ‚úÖ Contacts extracted: {processed}")
            self.log_sync_end(sync_id, 'completed', processed)
            return processed
            
        except Exception as e:
            logger.error(f"  ‚ùå Error extracting contacts: {e}")
            self.log_sync_end(sync_id, 'failed', processed, str(e))
            return processed
    
    def extract_deals(self) -> int:
        """–ò–∑–≤–ª–µ—á—å —Å–¥–µ–ª–∫–∏"""
        logger.info("üì• Extracting deals...")
        sync_id = self.log_sync_start('deals')
        
        processed = 0
        try:
            params = {}
            
            if SYNC_MODE == 'incremental':
                cutoff_time = (datetime.utcnow() - timedelta(hours=HOURS_BACK)).isoformat()
                params['filter'] = {'>DATE_MODIFY': cutoff_time}
            
            deals = self.bitrix_request('crm.deal.list', params)
            
            batch = []
            
            for deal in deals:
                deal_data = {
                    'id': self.safe_int(deal['ID']),
                    'title': deal.get('TITLE') or None,
                    'stage_id': deal.get('STAGE_ID') or None,
                    'stage_semantic_id': deal.get('STAGE_SEMANTIC_ID') or None,
                    'probability': self.safe_int(deal.get('PROBABILITY')),
                    'opportunity': self.safe_float(deal.get('OPPORTUNITY')),
                    'currency_id': deal.get('CURRENCY_ID') or 'RUB',
                    'is_manual_opportunity': self.safe_bool(deal.get('IS_MANUAL_OPPORTUNITY')),
                    'tax_value': self.safe_float(deal.get('TAX_VALUE')),
                    'company_id': self.safe_int(deal.get('COMPANY_ID')),
                    'contact_id': self.safe_int(deal.get('CONTACT_ID')),
                    'assigned_by_id': self.safe_int(deal.get('ASSIGNED_BY_ID')),
                    'created_by_id': self.safe_int(deal.get('CREATED_BY_ID')),
                    'closed': self.safe_bool(deal.get('CLOSED')),
                    'begindate': self.safe_datetime(deal.get('BEGINDATE')),
                    'closedate': self.safe_datetime(deal.get('CLOSEDATE')),
                    'date_create': self.safe_datetime(deal.get('DATE_CREATE')),
                    'date_modify': self.safe_datetime(deal.get('DATE_MODIFY')),
                    'utm_source': deal.get('UTM_SOURCE') or None,
                    'utm_medium': deal.get('UTM_MEDIUM') or None,
                    'utm_campaign': deal.get('UTM_CAMPAIGN') or None,
                    'utm_content': deal.get('UTM_CONTENT') or None,
                    'utm_term': deal.get('UTM_TERM') or None,
                    'source_id': deal.get('SOURCE_ID') or None,
                    'source_description': deal.get('SOURCE_DESCRIPTION') or None,
                    'raw_data': deal
                }
                
                batch.append(deal_data)
                processed += 1
                
                if len(batch) >= 50:
                    self.supabase.table('deals').upsert(batch).execute()
                    logger.info(f"  üìä Deals extracted: {processed}")
                    batch = []
            
            if batch:
                self.supabase.table('deals').upsert(batch).execute()
            
            logger.info(f"  ‚úÖ Deals extracted: {processed}")
            self.log_sync_end(sync_id, 'completed', processed)
            return processed
            
        except Exception as e:
            logger.error(f"  ‚ùå Error extracting deals: {e}")
            self.log_sync_end(sync_id, 'failed', processed, str(e))
            return processed
    
    def extract_activities(self) -> int:
        """–ò–∑–≤–ª–µ—á—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–∑–≤–æ–Ω–∫–∏, –≤—Å—Ç—Ä–µ—á–∏, email)"""
        logger.info("üì• Extracting activities...")
        sync_id = self.log_sync_start('activities')
        
        processed = 0
        try:
            params = {}
            
            if SYNC_MODE == 'incremental':
                cutoff_time = (datetime.utcnow() - timedelta(hours=HOURS_BACK)).isoformat()
                params['filter'] = {'>LAST_UPDATED': cutoff_time}
            
            activities = self.bitrix_request('crm.activity.list', params)
            
            batch = []
            
            for activity in activities:
                # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–≤–æ–Ω–∫–∞
                call_duration = None
                if activity.get('PROVIDER_ID') == 'VOXIMPLANT':
                    call_duration = self.safe_int(activity.get('RESULT_VALUE'))
                
                activity_data = {
                    'id': self.safe_int(activity['ID']),
                    'owner_id': self.safe_int(activity.get('OWNER_ID')),
                    'owner_type_id': self.safe_int(activity.get('OWNER_TYPE_ID')),
                    'type_id': self.safe_int(activity.get('TYPE_ID')),
                    'provider_id': activity.get('PROVIDER_ID') or None,
                    'provider_type_id': activity.get('PROVIDER_TYPE_ID') or None,
                    'subject': activity.get('SUBJECT') or None,
                    'description': activity.get('DESCRIPTION') or None,
                    'description_type': activity.get('DESCRIPTION_TYPE') or None,
                    'direction': self.safe_int(activity.get('DIRECTION')),
                    'priority': self.safe_int(activity.get('PRIORITY')),
                    'status': self.safe_int(activity.get('STATUS')),
                    'completed': self.safe_bool(activity.get('COMPLETED')),
                    'start_time': self.safe_datetime(activity.get('START_TIME')),
                    'end_time': self.safe_datetime(activity.get('END_TIME')),
                    'deadline': self.safe_datetime(activity.get('DEADLINE')),
                    'created': self.safe_datetime(activity.get('CREATED')),
                    'last_updated': self.safe_datetime(activity.get('LAST_UPDATED')),
                    'responsible_id': self.safe_int(activity.get('RESPONSIBLE_ID')),
                    'author_id': self.safe_int(activity.get('AUTHOR_ID')),
                    'call_duration': call_duration,
                    'raw_data': activity
                }
                
                batch.append(activity_data)
                processed += 1
                
                if len(batch) >= 50:
                    self.supabase.table('activities').upsert(batch).execute()
                    logger.info(f"  üìä Activities extracted: {processed}")
                    batch = []
            
            if batch:
                self.supabase.table('activities').upsert(batch).execute()
            
            logger.info(f"  ‚úÖ Activities extracted: {processed}")
            self.log_sync_end(sync_id, 'completed', processed)
            return processed
            
        except Exception as e:
            logger.error(f"  ‚ùå Error extracting activities: {e}")
            self.log_sync_end(sync_id, 'failed', processed, str(e))
            return processed
    
    # ==================== –†–ê–°–ß–Å–¢ –ü–ê–¢–¢–ï–†–ù–û–í ====================
    
    def calculate_patterns(self):
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–¥–µ–ª–æ–∫"""
        logger.info("üîÑ Calculating deal patterns...")
        
        try:
            # –ü—Ä—è–º–æ–π SQL —á–µ—Ä–µ–∑ postgrest
            # –í–º–µ—Å—Ç–æ RPC –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—ã–µ UPDATE/INSERT
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–¥–µ–ª–æ–∫
            deals_response = self.supabase.table('deals').select('id').execute()
            deal_ids = [d['id'] for d in deals_response.data]
            
            if not deal_ids:
                logger.info("  ‚ÑπÔ∏è No deals to calculate patterns")
                return
            
            # –î–ª—è –∫–∞–∂–¥–æ–π —Å–¥–µ–ª–∫–∏ —Å—á–∏—Ç–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            for deal_id in deal_ids:
                # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–¥–µ–ª–∫–∏
                activities = self.supabase.table('activities')\
                    .select('*')\
                    .eq('owner_id', deal_id)\
                    .eq('owner_type_id', 2)\
                    .execute()
                
                if not activities.data:
                    continue
                
                # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                touches_count = len(activities.data)
                calls_count = len([a for a in activities.data if a.get('type_id') == 2])
                emails_count = len([a for a in activities.data if a.get('type_id') == 4])
                meetings_count = len([a for a in activities.data if a.get('type_id') == 1])
                
                call_durations = [a.get('call_duration') for a in activities.data if a.get('call_duration')]
                avg_call_duration = sum(call_durations) / len(call_durations) if call_durations else None
                
                created_dates = [a.get('created') for a in activities.data if a.get('created')]
                first_activity_date = min(created_dates) if created_dates else None
                last_activity_date = max(created_dates) if created_dates else None
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω
                pattern_data = {
                    'deal_id': deal_id,
                    'touches_count': touches_count,
                    'calls_count': calls_count,
                    'emails_count': emails_count,
                    'meetings_count': meetings_count,
                    'avg_call_duration': avg_call_duration,
                    'first_activity_date': first_activity_date,
                    'last_activity_date': last_activity_date
                }
                
                self.supabase.table('deal_patterns').upsert(pattern_data).execute()
            
            logger.info(f"  ‚úÖ Patterns calculated for {len(deal_ids)} deals")
            
        except Exception as e:
            logger.error(f"  ‚ùå Error calculating patterns: {e}")
    
    # ==================== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–û–î–´ ====================
    
    def full_sync(self):
        """–ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("=" * 80)
        logger.info("üîÑ FULL SYNC STARTED")
        logger.info("=" * 80)
        
        start_time = time.time()
        
        managers_count = self.extract_managers()
        contacts_count = self.extract_contacts()
        deals_count = self.extract_deals()
        activities_count = self.extract_activities()
        
        self.calculate_patterns()
        
        duration = time.time() - start_time
        
        logger.info("=" * 80)
        logger.info("‚úÖ FULL SYNC COMPLETED")
        logger.info(f"   Duration: {duration:.2f}s")
        logger.info(f"   Managers: {managers_count}")
        logger.info(f"   Contacts: {contacts_count}")
        logger.info(f"   Deals: {deals_count}")
        logger.info(f"   Activities: {activities_count}")
        logger.info("=" * 80)
    
    def incremental_sync(self):
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è"""
        logger.info("=" * 80)
        logger.info(f"üîÑ INCREMENTAL SYNC STARTED (last {HOURS_BACK}h)")
        logger.info("=" * 80)
        
        start_time = time.time()
        
        contacts_count = self.extract_contacts()
        deals_count = self.extract_deals()
        activities_count = self.extract_activities()
        
        self.calculate_patterns()
        
        duration = time.time() - start_time
        
        logger.info("=" * 80)
        logger.info("‚úÖ INCREMENTAL SYNC COMPLETED")
        logger.info(f"   Duration: {duration:.2f}s")
        logger.info(f"   Contacts: {contacts_count}")
        logger.info(f"   Deals: {deals_count}")
        logger.info(f"   Activities: {activities_count}")
        logger.info("=" * 80)


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    logger.info("üöÄ Bitrix24 ETL Service initialized")
    logger.info(f"   Bitrix24: {BITRIX_WEBHOOK[:50]}...")
    logger.info(f"   Supabase: {SUPABASE_URL}")
    logger.info("")
    
    etl = Bitrix24ETL()
    
    if SYNC_MODE == 'full':
        etl.full_sync()
    elif SYNC_MODE == 'incremental':
        etl.incremental_sync()
    else:
        logger.error(f"‚ùå Unknown SYNC_MODE: {SYNC_MODE}")
        sys.exit(1)
    
    logger.info("üèÅ ETL process finished")


if __name__ == '__main__':
    main()